{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2ca5ba6",
   "metadata": {},
   "source": [
    "## Optimización de hiperparámetros\n",
    "\n",
    "La **optimización de hiperparámetros** (*HPO, Hyperparameter optimization*) es un mecanismo para aproximar una versión de un modelo con alto rendimiento y efectividad. Estos hiperparámetros, a diferencia de los parámetros de los modelos, son establecidos por el ingeniero antes del entrenamiento.\n",
    "\n",
    "### ¿Qué es un hiperparámetro?\n",
    "\n",
    "Un **hiperparámetro** (*hyperparameter*) es una variable de configuración externa al modelo que se utiliza para entrenarlo. Dependiendo del modelo, podemos encontrarnos multitud de hiperparámetros:\n",
    "\n",
    "- Tasa de aprendizaje en el descenso de gradiente.\n",
    "- Número de iteraciones en el descenso de gradiente.\n",
    "- Número de capas en una Red Neuronal.\n",
    "- Número de neuronas por capa en una Red Neuronal.\n",
    "- Número de agrupaciones (k) en un modelo k-NN."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b07965f7",
   "metadata": {},
   "source": [
    "#### Diferencia entre parámetro e hiperparámetro\n",
    "\n",
    "Un **parámetro** (*parameter*) de un modelo son las características que se optimizan para entrenarlo y que conforman su aprendizaje. Estos valores no son accesibles por nosotros como desarrolladores. Por ejemplo, en el caso de una regresión lineal, estos parámetros serán la pendiente y la intersección, por ejemplo.\n",
    "\n",
    "Con el conjunto de datos de entrenamiento y un algoritmo de aprendizaje (como el que vimos anteriormente sobre el *descenso del gradiente*), conseguimos alterar estos valores y que el modelo sepa clasificar o predecir los casos.\n",
    "\n",
    "Sin embargo, un híperparámetro, a diferencia, se establece antes de la fase de entrenamiento y permite al desarrollador crear un contexto y preparar al modelo.\n",
    "\n",
    "| Parámetro | Híperparámetro |\n",
    "|-----------|----------------|\n",
    "| Imprescindibles para realizar predicciones | Imprescindibles para inicializar los parámetros del modelo, que después serán optimizados |\n",
    "| Se estiman mediante algoritmos de aprendizaje (descenso del gradiente, Adam, Adagrad...) | Se estiman mediante el método de optimización |\n",
    "| No se establecen manualmente | Se establecen manualmente |\n",
    "| El valor final se obtiene después de la fase de aprendizaje y decidirán la precisión del modelo y cómo predecirá nuevos datos | La elección de estos valores decidirán cómo de eficiente será el entrenamiento. También tiene un gran impacto en el proceso de optimización de los parámetros |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cbd0897",
   "metadata": {},
   "source": [
    "### Proceso de optimización de hiperparámetros\n",
    "\n",
    "Normalmente, no conocemos los valores óptimos para los hiperparámetros que generarían el mejor de los resultados del modelo. Por lo tanto, es un paso vital e importante incluir este paso en toda construcción de un modelo de Machine Learning.\n",
    "\n",
    "Existen varias estrategias para llevarlo a cabo. Primero, entrenamos un modelo base:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7205e4ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8473282442748091"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "train_data = pd.read_csv(\"https://raw.githubusercontent.com/4GeeksAcademy/machine-learning-content/master/assets/clean_titanic_train.csv\")\n",
    "test_data = pd.read_csv(\"https://raw.githubusercontent.com/4GeeksAcademy/machine-learning-content/master/assets/clean_titanic_test.csv\")\n",
    "\n",
    "X_train = train_data.drop([\"Survived\"], axis = 1)\n",
    "y_train = train_data[\"Survived\"]\n",
    "X_test = test_data.drop([\"Survived\"], axis = 1)\n",
    "y_test = test_data[\"Survived\"]\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "base_accuracy = accuracy_score(y_test, y_pred)\n",
    "base_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b168aaf",
   "metadata": {},
   "source": [
    "Como vemos, la precisión \"base\", utilizando la configuración por defecto del modelo es de un 84,7%. Vamos a ver si podemos mejorar estos resultados utilizando las distintas técnicas.\n",
    "\n",
    "#### 1. Búsqueda en malla\n",
    "\n",
    "La **búsqueda en malla** (*grid search*) es un método que realiza una búsqueda exhaustiva a través de un subconjunto específico (establecido manualmente) de valores y luego probar todas las posibles combinaciones hasta encontrar el mejor de los modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3bca550f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=LogisticRegression(),\n",
       "             param_grid={&#x27;C&#x27;: [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
       "                         &#x27;penalty&#x27;: [&#x27;l1&#x27;, &#x27;l2&#x27;, &#x27;elasticnet&#x27;, None],\n",
       "                         &#x27;solver&#x27;: [&#x27;newton-cg&#x27;, &#x27;lbfgs&#x27;, &#x27;liblinear&#x27;, &#x27;sag&#x27;,\n",
       "                                    &#x27;saga&#x27;]},\n",
       "             scoring=&#x27;accuracy&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=LogisticRegression(),\n",
       "             param_grid={&#x27;C&#x27;: [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
       "                         &#x27;penalty&#x27;: [&#x27;l1&#x27;, &#x27;l2&#x27;, &#x27;elasticnet&#x27;, None],\n",
       "                         &#x27;solver&#x27;: [&#x27;newton-cg&#x27;, &#x27;lbfgs&#x27;, &#x27;liblinear&#x27;, &#x27;sag&#x27;,\n",
       "                                    &#x27;saga&#x27;]},\n",
       "             scoring=&#x27;accuracy&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=LogisticRegression(),\n",
       "             param_grid={'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
       "                         'penalty': ['l1', 'l2', 'elasticnet', None],\n",
       "                         'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag',\n",
       "                                    'saga']},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Definimos los parámetros a mano que queremos ajustar\n",
    "hyperparams = {\n",
    "    \"C\": [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
    "    \"penalty\": [\"l1\", \"l2\", \"elasticnet\", None],\n",
    "    \"solver\": [\"newton-cg\", \"lbfgs\", \"liblinear\", \"sag\", \"saga\"]\n",
    "}\n",
    "\n",
    "# Inicializamos la grid\n",
    "grid = GridSearchCV(model, hyperparams, scoring = \"accuracy\", cv = 5)\n",
    "grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9473ea5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores hiperparámetros: {'C': 10, 'penalty': 'l1', 'solver': 'liblinear'}\n"
     ]
    }
   ],
   "source": [
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Mejores hiperparámetros: {grid.best_params_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e758dabe",
   "metadata": {},
   "source": [
    "Como vemos, los parámetros optimizados utilizando esta técnica son:\n",
    "\n",
    "- `C`: 10\n",
    "- `penalty`: l1\n",
    "- `solver`: liblinear\n",
    "\n",
    "Además, siempre debemos utilizar el conjunto de datos de entrenamiento para ajustarlo. Ahora solo tenemos que repetir el entrenamiento estableciendo estos parámetros en el modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "52305d12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.851145038167939"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_grid = LogisticRegression(penalty = \"l1\", C = 10, solver = \"liblinear\")\n",
    "model_grid.fit(X_train, y_train)\n",
    "y_pred = model_grid.predict(X_test)\n",
    "\n",
    "grid_accuracy = accuracy_score(y_test, y_pred)\n",
    "grid_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2293a83",
   "metadata": {},
   "source": [
    "Observamos una mejora de poco menos de un 1%, pero esto en un dataset del mundo real es una grandísima victoria!\n",
    "\n",
    "Además, hemos utilizado tres de los muchos hiperparámetros que acepta este modelo. Podríamos construir un grid mucho más complejo (y que tardaría más en ejecutar) para mejorar los resultados.\n",
    "\n",
    "##### Pros y contras de esta estrategia\n",
    "\n",
    "Como puntos a favor podemos encontrar:\n",
    "- Exhaustividad: Prueba todas las combinaciones posibles de hiperparámetros dentro de la malla proporcionada, por lo que si la combinación óptima está dentro de ella, esta metodología la encontrará.\n",
    "- Reproducibilidad: Debido a su naturaleza determinista (no aleatoria), siempre se obtendrá el mismo resultado con los mismos parámetros e input.\n",
    "\n",
    "Sin embargo, caben destacar los siguientes puntos negativos:\n",
    "- Eficiencia: Es muy costoso computacionalmente. Puede llevar mucho tiempo y requerir muchos recursos, especialmente si la cantidad de hiperparámetros es grande y/o el rango de valores es amplio.\n",
    "- No garantiza llegar al mejor de los resultados, ya que depende de los hiperparámetros y de los valores que el desarrollador establezca."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "147175e7",
   "metadata": {},
   "source": [
    "#### 2. Búsqueda aleatoria\n",
    "\n",
    "La **búsqueda aleatoria** (*random search*) es similar al anterior pero, en lugar de probar todas las combinaciones posibles de unos valores de hiperparámetros previamente establecidos, esta metodología selecciona aleatoriamente combinaciones de hiperparámetros para probar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8aa61c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=5, estimator=LogisticRegression(), n_iter=100,\n",
       "                   param_distributions={&#x27;C&#x27;: array([1.00000000e-04, 2.63665090e-04, 6.95192796e-04, 1.83298071e-03,\n",
       "       4.83293024e-03, 1.27427499e-02, 3.35981829e-02, 8.85866790e-02,\n",
       "       2.33572147e-01, 6.15848211e-01, 1.62377674e+00, 4.28133240e+00,\n",
       "       1.12883789e+01, 2.97635144e+01, 7.84759970e+01, 2.06913808e+02,\n",
       "       5.45559478e+02, 1.43844989e+03, 3.79269019e+03, 1.00000000e+04]),\n",
       "                                        &#x27;penalty&#x27;: [&#x27;l1&#x27;, &#x27;l2&#x27;, &#x27;elasticnet&#x27;,\n",
       "                                                    None],\n",
       "                                        &#x27;solver&#x27;: [&#x27;newton-cg&#x27;, &#x27;lbfgs&#x27;,\n",
       "                                                   &#x27;liblinear&#x27;, &#x27;sag&#x27;,\n",
       "                                                   &#x27;saga&#x27;]},\n",
       "                   random_state=42, scoring=&#x27;accuracy&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=5, estimator=LogisticRegression(), n_iter=100,\n",
       "                   param_distributions={&#x27;C&#x27;: array([1.00000000e-04, 2.63665090e-04, 6.95192796e-04, 1.83298071e-03,\n",
       "       4.83293024e-03, 1.27427499e-02, 3.35981829e-02, 8.85866790e-02,\n",
       "       2.33572147e-01, 6.15848211e-01, 1.62377674e+00, 4.28133240e+00,\n",
       "       1.12883789e+01, 2.97635144e+01, 7.84759970e+01, 2.06913808e+02,\n",
       "       5.45559478e+02, 1.43844989e+03, 3.79269019e+03, 1.00000000e+04]),\n",
       "                                        &#x27;penalty&#x27;: [&#x27;l1&#x27;, &#x27;l2&#x27;, &#x27;elasticnet&#x27;,\n",
       "                                                    None],\n",
       "                                        &#x27;solver&#x27;: [&#x27;newton-cg&#x27;, &#x27;lbfgs&#x27;,\n",
       "                                                   &#x27;liblinear&#x27;, &#x27;sag&#x27;,\n",
       "                                                   &#x27;saga&#x27;]},\n",
       "                   random_state=42, scoring=&#x27;accuracy&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=LogisticRegression(), n_iter=100,\n",
       "                   param_distributions={'C': array([1.00000000e-04, 2.63665090e-04, 6.95192796e-04, 1.83298071e-03,\n",
       "       4.83293024e-03, 1.27427499e-02, 3.35981829e-02, 8.85866790e-02,\n",
       "       2.33572147e-01, 6.15848211e-01, 1.62377674e+00, 4.28133240e+00,\n",
       "       1.12883789e+01, 2.97635144e+01, 7.84759970e+01, 2.06913808e+02,\n",
       "       5.45559478e+02, 1.43844989e+03, 3.79269019e+03, 1.00000000e+04]),\n",
       "                                        'penalty': ['l1', 'l2', 'elasticnet',\n",
       "                                                    None],\n",
       "                                        'solver': ['newton-cg', 'lbfgs',\n",
       "                                                   'liblinear', 'sag',\n",
       "                                                   'saga']},\n",
       "                   random_state=42, scoring='accuracy')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Definimos los parámetros que queremos ajustar\n",
    "hyperparams = {\n",
    "    \"C\": np.logspace(-4, 4, 20),\n",
    "    \"penalty\": [\"l1\", \"l2\", \"elasticnet\", None],\n",
    "    \"solver\": [\"newton-cg\", \"lbfgs\", \"liblinear\", \"sag\", \"saga\"]\n",
    "}\n",
    "\n",
    "# Inicializamos la búsqueda aleatoria\n",
    "random_search = RandomizedSearchCV(model, hyperparams, n_iter = 100, scoring = \"accuracy\", cv = 5, random_state = 42)\n",
    "random_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f00445fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores hiperparámetros: {'solver': 'lbfgs', 'penalty': 'l2', 'C': 29.763514416313132}\n"
     ]
    }
   ],
   "source": [
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Mejores hiperparámetros: {random_search.best_params_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeaf3469",
   "metadata": {},
   "source": [
    "Como vemos, los parámetros optimizados utilizando esta técnica son:\n",
    "\n",
    "- `C`: 29.7635\n",
    "- `penalty`: l2\n",
    "- `solver`: lbfgs\n",
    "\n",
    "Además, podemos apreciar en los logs que ha habido algunos errores debido a incompatibilidades entre atributos (valores de un atributo que son incompatibles con valores de otro). Esto es manejado por la propia función de estimación y no debemos preocuparnos, ya que siempre nos va a devolver la mejor de las soluciones sin fallos.\n",
    "\n",
    "Con esta nueva hiperparametrización, reentrenamos el modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d09c7485",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.851145038167939"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_random_search = LogisticRegression(penalty = \"l2\", C = 29.7635, solver = \"lbfgs\")\n",
    "model_random_search.fit(X_train, y_train)\n",
    "y_pred = model_random_search.predict(X_test)\n",
    "\n",
    "random_search_accuracy = accuracy_score(y_test, y_pred)\n",
    "random_search_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00262ae7",
   "metadata": {},
   "source": [
    "Como vemos, arroja el mismo nivel de precisión que la estrategia anterior. Esto quiere decir que con los medios e hiperparámetros que hemos intentado optimizar nos encontramos en un **máximo local**, esto es, que tendríamos que repetir la estrategia de optimización incluyendo otros hiperparámetros para mejorar los resultados del modelo, ya que solo jugando con el `penalty`, `C` y `solver` no vamos a mejorar el modelo más de lo que ya está.\n",
    "\n",
    "##### Pros y contras de esta estrategia\n",
    "\n",
    "Como puntos a favor podemos encontrar:\n",
    "- Eficiencia: Por lo general, es más rápido que el grid search, ya que no prueba todas las combinaciones posibles, sino que selecciona aleatoriamente un número concreto de ellas.\n",
    "- Puede acercarse más a la optimización global al seleccionar valores aleatorios, ya que no hay una malla fija de ellos..\n",
    "\n",
    "Como puntos desfavorables podemos encontrar:\n",
    "- Aleatoriedad. No garantiza la misma solución en cada ejecución, a menos que se fije una semilla (`random_state`).\n",
    "- No es exhaustivo: Puede que no pruebe la mejor combinación de hiperparámetros si tiene la mala suerte con la selección aleatoria."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c1802b3",
   "metadata": {},
   "source": [
    "#### ¿Cuándo utilizar cada estrategia?\n",
    "\n",
    "Ambas son técnicas de búsqueda de hiperparámetros y pueden ser útiles en diferentes situaciones. La búsqueda en malla es más adecuada cuando tenemos un conjunto pequeño y bien definido de hiperparámetros, y la búsqueda aleatoria es más útil cuando existe un espacio de hiperparámetros grande y/o no tenemos una idea clara de cuáles podrían ser los mejores valores a optimizar."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 64-bit ('3.8.13')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "110cc1dee26208153f2972f08a2ad52b6a56238dc66d48e87fb757ef2996db56"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
