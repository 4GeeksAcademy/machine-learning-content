{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5209ddf3",
   "metadata": {},
   "source": [
    "## Logistic regression\n",
    "\n",
    "**Logistic regression** is a Machine Learning technique used to find the relationships between two variables and predict the value of one of them as a function of the other. Normally, this prediction has only two possible outcomes, such as predicting the sex of a person (female or male), the outcome of an experiment (success or failure), and so on.\n",
    "\n",
    "Moreover, this prediction is obtained in terms of probability, that is, the probability that a given outcome will occur in a dichotomous event. This probability can then be modified to generate the prediction of a class.\n",
    "\n",
    "This Machine Learning algorithm is usually the first to be studied for simplicity and fundamentalism. It is also very easy to implement."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9289fc2e",
   "metadata": {},
   "source": [
    "### Model parameterization\n",
    "\n",
    "All Machine Learning models have a large number of parameters, vital for their application to different use cases and data sets. The choice of these parameters will depend on the data set and the specific problem we are trying to solve. It is advisable to try different values and validations in order to always obtain the best possible model.\n",
    "\n",
    "We can easily build a logistic regression model in Python using the `scikit-learn` library and the `LogisticRegression` function. Some of its most important parameters and the first ones we should focus on are:\n",
    "\n",
    "- `penalty`: This parameter is used to prevent model overfitting, which is when the model learns so much from the training data that it is not able to generalize and only predicts those data well and not new ones. This parameter can be configured so that there is no penalty and to graduate it from very slight to very high levels.\n",
    "- `C`: This parameter determines the complexity of the model. It is the inverse of the previous parameter. It is a decimal number that determines how simple we want the model to be. The higher the number, the more complex the model will be and the more it will fit the training sample (increasing the probability of [overfitting](https://4geeks.com/lesson/machine-learning-basics#Model-overfitting)).\n",
    "- `solver`: Regression algorithm that will be used to train the model. Depending on the size of the data set, the classes to predict, the level of overfitting, or the level of accuracy we are willing to assume, we will choose one implementation or another.\n",
    "- `max_iter`: Maximum number of iterations.\n",
    "\n",
    "Another very important parameter is the `random_state`, which controls the random generation seed required by some of the model solvers. This parameter is crucial to ensuring replicability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b7a725",
   "metadata": {},
   "source": [
    "### Model usage\n",
    "\n",
    "Each model has certain requirements regarding the content and form of the input to ensure that the results of the model are the best possible. In the case of logistic regression, they are as follows:\n",
    "\n",
    "- Identify and maintain the dependent variables. Logistic regression works well when a direct relationship between the value of a variable and the value of the class is identified. That is, if we want to classify a patient as healthy/unhealthy, a variable that would indicate his status would be sick/not sick, for example. These types of variables should be maintained.\n",
    "- Perform a correct EDA. It is vital to apply this process to eliminate noise, duplicates, and normalize the characteristics. This model only works with numerical variables.\n",
    "- Stratified sample size. This model performs best when it has (approximately) the same number of records from one class and another. In addition, it must have a sufficient sample to train, with as many different casuistries as possible in order to generalize and maximize its learning.\n",
    "\n",
    "#### Application to the Titanic dataset\n",
    "\n",
    "In the Titanic data set, we have more than one characteristic, and with logistic regression we predict whether they will survive or not. If the value predicted by the model were 0.85, that would mean that the person has an 85% chance of surviving and a 15% chance of not surviving. Thus, we must establish a limit (*threshold*) to be able to perform the classification (we answer the following question: from what probability value can we assume that the person survives or not?). Let us assume that this value is 50%, i.e. when the probability is greater than or equal to 0.5, the value is 1 (he/she survives), and when the probability is less than 0.5, the value is 0 (he/she does not survive).\n",
    "\n",
    "In addition, we also need to know that the process of training and using the model comes after the exploratory analysis (EDA), so we will need to start from there.\n",
    "\n",
    "##### Step 1: Reading the processed dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c1bcee3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Sex_n</th>\n",
       "      <th>Embarked_n</th>\n",
       "      <th>FamMembers</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.020495</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.050749</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.015127</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.032596</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.067096</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pclass      Fare  Sex_n  Embarked_n  FamMembers  Survived\n",
       "0     0.5  0.020495    1.0    0.333333         0.0         0\n",
       "1     0.5  0.050749    0.0    0.333333         0.1         1\n",
       "2     1.0  0.015127    1.0    1.000000         0.0         1\n",
       "3     1.0  0.032596    1.0    0.333333         0.2         1\n",
       "4     1.0  0.067096    1.0    0.333333         0.4         0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_data = pd.read_csv(\"https://raw.githubusercontent.com/4GeeksAcademy/machine-learning-content/master/assets/clean_titanic_train.csv\")\n",
    "test_data = pd.read_csv(\"https://raw.githubusercontent.com/4GeeksAcademy/machine-learning-content/master/assets/clean_titanic_test.csv\")\n",
    "\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fd150c6",
   "metadata": {},
   "source": [
    "We will use the `train` set to train the model, while with the `test` we will evaluate it to measure its degree of effectiveness. We will also split the predictors of the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b49ce3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_data.drop([\"Survived\"], axis = 1)\n",
    "y_train = train_data[\"Survived\"]\n",
    "X_test = test_data.drop([\"Survived\"], axis = 1)\n",
    "y_test = test_data[\"Survived\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e18388a",
   "metadata": {},
   "source": [
    "##### Step 2: Initialization and training of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a451baa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f51ca60",
   "metadata": {},
   "source": [
    "The training time of a model will depend, first of all, on the size of the dataset (instances and features), and also on the model type and its configuration.\n",
    "\n",
    "##### Step 3: Model prediction\n",
    "\n",
    "Once the model has been trained, it can be used to predict with the test data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0047034d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0,\n",
       "       0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0,\n",
       "       1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1,\n",
       "       0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1,\n",
       "       0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1,\n",
       "       1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1,\n",
       "       0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0,\n",
       "       0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37261ff7",
   "metadata": {},
   "source": [
    "With raw data it is very difficult to know whether the model is getting it right or not. To do this, we must compare it with reality. There are many metrics to measure the effectiveness of a model in predicting, including **accuracy**, which is the fraction of predictions that the model makes correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f0dd29ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8473282442748091"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae94a930",
   "metadata": {},
   "source": [
    "The above value would be interpreted as the model having predicted, out of 262 passengers, the survival outcome of 222 of them (whether they survived or not) correctly.\n",
    "\n",
    "In addition to the observed model score, it is common in classification problems to construct a **confusion matrix**, which is a table that is organized such that each row of the matrix represents instances of a predicted class, while each column represents instances of an actual class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d7cc34b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 300x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "titanic_cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Let's draw this matrix to make it more visual\n",
    "cm_df = pd.DataFrame(titanic_cm)\n",
    "\n",
    "plt.figure(figsize = (3, 3))\n",
    "sns.heatmap(cm_df, annot=True, fmt=\"d\", cbar=False)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b83e73ee",
   "metadata": {},
   "source": [
    "The interpretation of a confusion matrix is as follows:\n",
    "\n",
    "- **True positive** (*TP*): corresponds to the number `142` and are the cases where the model predicted positive (no survival) and the actual class is also positive.\n",
    "- **True negative** (*TN*): Corresponds to the number `80` and are the cases where the model predicted negative (survival) and the actual class is also negative.\n",
    "- **False positive** (*FP*): Corresponds to the number `23` and are the cases in which the model predicted positive, but the actual class is negative.\n",
    "- **False negative** (*FN*): Corresponds to the number `17` and are the cases where the model predicted negative, but the actual class is positive.\n",
    "\n",
    "These four measures are often used to calculate more complex metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0aaf11a",
   "metadata": {},
   "source": [
    "##### Step 4: Optimization of results\n",
    "\n",
    "As we have seen, the base model (with all predefined parameters) of the logistic regression obtains just over 84% accuracy. However, modifying the model parameters could lead to a significant improvement (or worsening) of the results. There are several strategies, such as regularized models."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 64-bit ('3.8.13')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "110cc1dee26208153f2972f08a2ad52b6a56238dc66d48e87fb757ef2996db56"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
