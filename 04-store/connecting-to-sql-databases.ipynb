{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9ebad92",
   "metadata": {},
   "source": [
    "# How to connect to SQL databases using Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a493f5a9",
   "metadata": {},
   "source": [
    "As machine learning engineers we will probably have to interact with SQL databases in order to access data. SQL means Structured Query Language. The key difference between SQL and Python is that developers use SQL to access and extract data from a database, whereas developers use Python to analyze and manipulate data by running regression tests, time series tests and other data processing computations.\n",
    "\n",
    "Some popular SQL databases are SQLite, PostgreSQL, MySQL. SQLite is best known for being an integrated database. This means that we don't have to install an extra application or use a separate server to run the database. It moves fast but has limited functionality, so if we dont' need a ton of data storage space, we will want to use a SQLite database. On the other hand, PostgreSQL and MySQL have database types that are great for enterprise solutions. If we need to scale fast, MySQL and PostgreSQL are the best bet. They'll provide long-term infrastructure, bolster security, and handle high performance activities.\n",
    "\n",
    "In this lecture we'll see how Python and some SQL databases interact. Why should we care about connecting Python and a SQL database?\n",
    "\n",
    "Perhaps, as machine learning engineers, we will need to build an automated ETL pipeline. Connecting Python to a SQL database will allow us to use Python for its automation capabilities. We'll also be able to communicate between different data sources. We won't have to switch between different programming languages, we'll be able to use our Python skills to manipulate data from a SQL database. We won't need a CSV file.\n",
    "\n",
    "The important thing to remember is that Python can integrate with each database type. Python and SQL databases connect through custom Python libraries. You can import these libraries into your Python script.\n",
    "\n",
    "**The following is a code example on how to connect to a SQL database:**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "766374bb",
   "metadata": {},
   "source": [
    "\n",
    "```py\n",
    "from dbmodule import connect \n",
    "\n",
    "#Create a connection object\n",
    "\n",
    "CONNECTION = CONNECT('databse name', 'username','password')\n",
    "\n",
    "#Create a cursor object\n",
    "\n",
    "CURSOR = CONNECTION.CURSOR()\n",
    "\n",
    "#Run queries\n",
    "\n",
    "CURSOR.EXECUTE('select * from mytable')\n",
    "RESULTS = CURSOR.FETCHALL()\n",
    "\n",
    "#Free resources\n",
    "CURSOR.CLOSE()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0158aa9",
   "metadata": {},
   "source": [
    "**Example code to connect to a PostreSQL database and store data in a pandas dataframe:**\n",
    "\n",
    "In this case, we chose AWS Redshift. We will import the psycopg library. This library translates the Python code we write to speak to the PostgreSQL database (AWS Redshift).\n",
    "\n",
    "Otherwise, AWS Redshift would not understand our Python code. But because of the psycopg library, we will now speak a language AWS Redshift can understand."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce14dbb",
   "metadata": {},
   "source": [
    "```py\n",
    "#Library for connecting to AWS Redshift\n",
    "import psycopg\n",
    "\n",
    "#Library for reading the config file, which is in JSON\n",
    "import json\n",
    "\n",
    "#Data manipulation library\n",
    "import pandas as pd\n",
    "```\n",
    "\\\n",
    "We imported JSON because creating a JSON config file is a secure way to store your database credentials. We don't want anyone else eyeing those! The json.load() function reads the JSON file so we can access our database credentials in the next step.\n",
    "\n",
    "```py\n",
    "config_file = open(r\"C:\\Users\\yourname\\config.json\")\n",
    "config = json.load(config_file)\n",
    "```\n",
    "\\\n",
    "Now we want to create a databse connection. We'll need to read and use the credentials from our config file:\n",
    "\n",
    "```py\n",
    "con = psycopg2.connect(dbname= \"db_name\", host=config[hostname], port = config[\"port\"],user=config[\"user_id\"], password=config[\"password_key\"])\n",
    "cur = con.cursor()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7329110a",
   "metadata": {},
   "source": [
    "### Creating and connecting to a SQLite database using Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e32bca37",
   "metadata": {},
   "source": [
    "As we already mentioned, SQLite is a Relation Database Management System that is lightweight and easy to set up. SQLite is serverless, which is its biggest advantage. It does not require a server to run a database, unlike other RDMS like MySQL or PostgreSQL. So we donâ€™t need any installation setup.\n",
    "\n",
    "SQLite databases are stored locally, with files stored in the disk. This makes accessing and managing the data in the database is remarkably fast.\n",
    "\n",
    "**Example code to create a database:**\n",
    "\n",
    "```py\n",
    "import sqlite3\n",
    "\n",
    "connection = sqlite3.connect('shows.db')  #creating a database with name:\n",
    "cursor = connection.cursor()   #create a cursor object in order to create a table\n",
    "cursor.execute('''CREATE TABLE IF NOT EXISTS Shows\n",
    "              (Title TEXT, Director TEXT, Year INT)''')  #create a table with column names and data types\n",
    "\n",
    "connection.commit()  #commit the changes in the database\n",
    "connection.close()  #close the connection\n",
    "```\n",
    "\n",
    "After running the file, in your current project directory, one file is created called shows.db. This is the SQLite database file generated by Python.\n",
    "\n",
    "\n",
    "**Example code to connect to the database:**\n",
    "\n",
    "```py\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    " \n",
    "# Create engine: engine\n",
    "engine = create_engine('sqlite:///databse_name.sqlite')\n",
    " \n",
    "# Save the table names to a list: table_names\n",
    "table_names = engine.table_names()\n",
    " \n",
    "# Print the table names to the shell\n",
    "print(table_names)\n",
    " \n",
    "# Open engine connection: con,  and select specified columns and number of rows\n",
    "\n",
    "with engine.connect() as con:\n",
    "    ab = con.execute(\"SELECT Title, Director FROM Shows\")\n",
    "    df = pd.DataFrame(ab.fetchmany(size=5))\n",
    "    df.columns = ab.keys()\n",
    "\n",
    "# Close connection\n",
    "con.close()\n",
    " \n",
    "# Print first rows of dataframe\n",
    "print(df.head())\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b32a462c",
   "metadata": {},
   "source": [
    "### Connecting to a DB2 Database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e912c9d4",
   "metadata": {},
   "source": [
    "IBM Db2 is a family of data management products, including the Db2 relational database. The free plan provides 200 MB of data storage on the cloud. In order to practice creating a SQL database and writing SQL queries, this is a good place to start. \n",
    "\n",
    "We can create our tables on the cloud or directly from our notebook using Python. In order to do it with python, we first need to connect to our cloud database using the credentials provided to us in the moment the database instance was created."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a3658b",
   "metadata": {},
   "source": [
    "To connect to a DB2, it requires the following information:\n",
    "\n",
    "- controler name\n",
    "- database name\n",
    "- DNS host name or IP\n",
    "- Host port\n",
    "- Connection protocol\n",
    "- User id\n",
    "- Password\n",
    "\n",
    "Example to create a database connection: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e573e4f8",
   "metadata": {},
   "source": [
    "```py\n",
    "#Create database connection\n",
    "\n",
    "dsn = (\n",
    "    \"Driver = { {IBM DB2 ODBC DRIVER}};\"\n",
    "    \"Database = {0};\"\n",
    "    \"HOSTNAME = {1};\"\n",
    "    \"PORT = {2};\"\n",
    "    \"PROTOCOL = TCPIP;\"\n",
    "    \"UID = {3};\"\n",
    "    \"PWD = {4};\").format(dsn_database, dsn_hostname, dsn_port, dsn_uid, dsn_pwd)\n",
    "\n",
    "try: \n",
    "    conn = ibm_db.connect(dsn, \" \", \" \")\n",
    "    print(\"Connected!\")\n",
    "    \n",
    "except:\n",
    "    print(\"Unable to connect to database\")\n",
    "    \n",
    "#Close the database connection\n",
    "\n",
    "ibm_db.close(conn)\n",
    "\n",
    "#Note: It is always important to close the connections to avoid non used connectors taking resources.\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0691d4ef",
   "metadata": {},
   "source": [
    "**How to create a table from python**\n",
    "\n",
    "ibm_db.exec_inmediate()  --> function of the ibm_db API\n",
    "\n",
    "Parameters for the function:\n",
    "\n",
    "- connection\n",
    "- statement\n",
    "- options\n",
    "\n",
    "Example: Creating a table called CARS in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bd066d8",
   "metadata": {},
   "source": [
    "\n",
    "#CREATE TABLE\n",
    "```py\n",
    "stmt = ibm_db.exec_inmediate(conn, \"CREATE TABLE Cars(\n",
    "    serial_no VARCHAR(20) PRIMARY KEY NOT NULL,\n",
    "    make varchar(20) NOT NULL,\n",
    "    model VARCHAR(20) NOT NULL,\n",
    "    car_class VARCHAR(20) NOT NULL)\"\n",
    "    )\n",
    "```\n",
    "\n",
    "#LOAD DATA IN TABLE\n",
    "```py\n",
    "stmt = ibm_db.exec_inmediate(conn, \"INSERT INTO Cars(\n",
    "    serial_no, make, model, car_class)\n",
    "    VALUES('A2345453','Ford','Mustang','class3');\")\n",
    "```\n",
    "\n",
    "#FETCH DATA FROM CARS TABLE\n",
    "```py\n",
    "stmt = ibm_db.exec_inmediate(conn, \"SELECT * FROM Cars\")\n",
    "\n",
    "ibm_db.fetch_both(stmt)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aef772d",
   "metadata": {},
   "source": [
    "**Using pandas to retrieve data from the tables**\n",
    "\n",
    "Example:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e40e5f7f",
   "metadata": {},
   "source": [
    "```py\n",
    "\n",
    "import pandas\n",
    "import ibm_db_dbi\n",
    "pconn = ibm_db_dbi.connection(conn)\n",
    "\n",
    "df = pandas.read_sql('SELECT * FROM Cars', pconn)\n",
    "df\n",
    "\n",
    "#Example of a plot\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns \n",
    "\n",
    "#categorical scatterplot\n",
    "\n",
    "plot = sns.swarmplot(x=\"Category\", y=\"Calcium\", data=df)\n",
    "plt.setp(plot.get_xticklabels(), rotation=70)\n",
    "plt.title('Calcium content')\n",
    "plt.show()\n",
    "\n",
    "#Making a boxplot\n",
    "#A boxplot is a graph that indicates the distribution of 1 or more variables. The box captures the median 50% of the data.\n",
    "# The line and dots indicate possible outliers and not normal values.\n",
    "\n",
    "plot = sns.set_style('Whitegrid')\n",
    "ax = sns.boxplot(x=df['glucose level'])\n",
    "plt.show()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e36ab48",
   "metadata": {},
   "source": [
    "**Getting the properties**\n",
    "\n",
    "DB2 --->  syscat.tables                                 \n",
    "\n",
    "SQL Server --->  information=schema.tables   \n",
    " \n",
    "Oracle --->  all_tables or user_tables\n",
    "\n",
    "Example:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec4ad7e",
   "metadata": {},
   "source": [
    "```py\n",
    "\n",
    "#Getting table properties from DB2\n",
    "\n",
    "SELECT * FROM syscat.tables\n",
    "#(this will show too many tables)\n",
    "\n",
    "SELECT tabschema, tabname, create_time\n",
    "FROM syscat.tables\n",
    "WHERE tabschema = 'ABC12345' #---> replace with your own DB2 username\n",
    "\n",
    "#Getting a list of columns in database\n",
    "\n",
    "SELECT * FROM syscat.columns\n",
    "WHERE tabname = 'Cats'\n",
    "\n",
    "#To obtain specific column properties:\n",
    "\n",
    "%sql SELECT DISTINCT(name), coltype, length\n",
    "    FROM sysibm.syscolumns\n",
    "    WHERE tbname = 'Cats'\n",
    "    \n",
    "%sql SELECT DISTINCT(name), coltype, length\n",
    "    FROM sysibm.syscolumns \n",
    "    WHERE tbname = 'Miami_crime_data'\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd12f5c",
   "metadata": {},
   "source": [
    "Source:\n",
    "\n",
    "https://www.freecodecamp.org/news/python-sql-how-to-use-sql-databases-with-python/#:~:text=Perhaps%20you%20work%20in%20data%20engineering%20and%20you,be%20able%20to%20communicate%20between%20different%20data%20sources."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
